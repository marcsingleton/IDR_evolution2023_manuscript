% Abstract must be 300 words or less
\begin{abstract}
\noindent
Identifying protein sequences with common ancestry is a core task in bioinformatics and evolutionary biology. However, methods for inferring and aligning such sequences in annotated genomes have not kept pace with the increasing scale and complexity of the available data. Thus, in this work we implemented several improvements to the traditional methodology that more fully leverage the redundancy of closely related genomes and the organization of their annotations. Two highlights include the application of the more flexible \textit{k}-clique percolation algorithm for identifying clusters of orthologous proteins and the development of a novel technique for removing poorly supported regions of alignments with a phylogenetic HMM. In making the latter, we also wrote a fully documented Python package Homomorph that implements standard HMM algorithms and created a set of tutorials to promote its use by a wide audience. We applied the resulting pipeline to a set of 33 annotated \textit{Drosophila} genomes, generating 22,813 orthologous groups and 8,565 high-quality alignments.
\end{abstract}

\section*{Introduction}
Comparative genomics is a powerful tool for yielding insights into evolutionary relationships, molecular function, and the forces that drive gene, genome, and population evolution. These methods often rely on the identification of homologous sequences or homologs, that is sequences with common ancestry, since this ensures that differences between sequences reflect variations in evolution from a common point of divergence. However, many analyses impose the additional condition that the sequences have diverged through speciation events (orthology) rather than duplications (paralogy) or other mechanisms such as horizontal gene transfer~\cite{Fitch1970}. The underlying assumption is ``orthologs'' have conserved equivalent functions whereas ``paralogs'', by virtue of their redundancy, are more likely to diverge~\cite{Ohno1970, Nowak1997, Altenhoff2012, Pegueroles2013, Soria2014}.\footnote{For multiple sequences, orthology is usually defined relative to their most recent common ancestor. This technically includes sequences which split by duplication after this point (``in-paralogs''), but excludes sequences which split by duplication before (``out-paralogs'') \cite{Remm2001}. Many current orthology inference pipelines explicitly incorporate steps to detect in-paralogs. However, the resulting orthologs groups can easily be restricted to those without in-paralogs (``single copy orthologs'') for analyses where an assumption of conserved function is necessary.} This relationship between orthology and function is an essential component of modern biological research since it permits the transfer of annotations between biological systems using sequence similarity alone.

Given this importance, methods for inferring orthologous groups of proteins were developed shortly after the first genomes were sequenced in the late 1990s~\cite{Fleischmann1995, Goffeau1996, CESC1998}. One early and influential approach was to cluster triangles of hits resulting from homology searches between pairs of genomes~\cite{Tatusov1997}. Graph-based approaches have remained popular, and in the intervening years many other researchers have refined this method by implementing various pre- and post-processing steps. Despite these improvements, many databases and pipelines use the same triangle clustering algorithm or other methods which require relatively few hits between sequences to infer an orthologous group, \textit{e.g.} connected components or Markov clustering~\cite{Remm2001, Enright2002, Li2003, Jensen2007, Linard2011, Emms2015, Train2017, Cosentino2018}. However, the scale of biological sequence data has changed dramatically. For example, in the last decade, the number of annotated genomes available from NCBI has increased nearly 20-fold and currently exceeds 900 (Fig.~\ref{sfig:ncbi}). Though this figure is only a rough proxy of the total number of assemblies available, it will likely continue to grow rapidly in the coming years as many large-scale genome assembly efforts such as i5K, the Bird 10,000 Genomes Project, and the Vertebrate Genomes Project have already yielded results~\cite{Thomas2020, Feng2020, Rhie2021}. Thus, the dense taxonomic sampling made possible by these projects poses new challenges and opportunities for the standard methods of orthology inference and alignment, which implicitly assume fewer and more distantly related genomes or fail to fully leverage the redundancy and organization of their annotations.

In this work we therefore developed a computational pipeline that can robustly infer and align orthologous groups of proteins even when the genomes are highly redundant. Like many other orthology inference pipelines, our overall approach is based on clustering a graph of hits from homology searches. However, we modified many details to maximize the detection of highly diverged orthologs while also minimizing the impact of incomplete or incorrect annotations. Furthermore, since modern genome annotation pipelines frequently produce gene models and protein sequences in tandem, we implemented an additional clustering step to organize the resulting orthologous groups of proteins into gene-level units. However, most of our efforts were focused on the final step of aligning the orthologous sequences. Though genome annotation pipelines are often proficient at identifying the overall locus of genes, the accurate identification of exon boundaries and start codons when transcript evidence is limited remains an ongoing challenge~\cite{Frankish2015, Dunne2018}. Consequently, protein sequences derived from annotation pipelines can include non-homologous segments of significant length or exclude highly conserved segments. Such heterogeneity in the structure and length of the sequences in an orthologous group poses many challenges for their alignment and subsequent analysis. Thus, we implemented several novel quality control and data cleaning steps to correct mis-alignments and identify likely sequencing, assembly, or annotation errors.

To develop these methods, we chose a set of 33 assembled and annotated \textit{Drosophila} genomes, which includes all 12 species from the original \textit{Drosophila} 12 Genomes Consortium~\cite{D12GC2007}. However, the genomes of these 12 species have been re-sequenced since their first release, which has resulted in substantial improvements in their assemblies and annotations. Despite these developments and other several other recent genome assembly projects of species in the \textit{Drosophila} genus, there is not yet a collection of high-quality alignments of orthologous proteins that reflects these improvements in genome assembly and diversity~\cite{Miller2018, Kim2021}. Given the \textit{Drosophila} genus spans diverse habitats and over 50 million years of evolution but maintains a conserved life cycle and body plan, such a resource would facilitate a new generation of studies that illuminate the forces that drive protein evolution in unprecedented detail~\cite{Wiegmann2011, Obbard2012}.

\begin{figure}[h!]
\includegraphics[width=\textwidth]{graphical_overview.png}
\centering
\caption{\textbf{Overview of homology inference pipeline.}
\textbf{(A-C)} The large, open circles represent the annotated genomes, and the small, filled circles represent the protein sequences associated with each annotation. Sequences that share homology are colored with shades of the same hue. \textbf{(D-F)} The small, filled circles and lines represent the same sequences and best hits from the previous steps.}
\label{fig:graphical_overview}
\end{figure}

\section*{Results}
\subsection*{Pipeline overview}
Our pipeline follows a similar overall approach to other graph-based methods of orthology inference. First, protein sequences from annotated genomes are collected (Fig.~\ref{fig:graphical_overview}A), and homology searches are then conducted between all query-target pairs of genomes (Fig.~\ref{fig:graphical_overview}B). The raw output from these homology searches is processed to yield best hits between pairs of sequences (Fig.~\ref{fig:graphical_overview}C). Next, the network of best hits is clustered into self-consistent orthologous groups (Fig.~\ref{fig:graphical_overview}D). Since genes can have multiplied associated isoforms, we then implemented a novel second clustering step where orthologous groups are grouped by their parent genes, which are represented by the two sets of clusters with warm and cool colors, respectively (Fig.~\ref{fig:graphical_overview}E). Finally, representative sequences in each orthologous group are aligned (Fig.~\ref{fig:graphical_overview}F). In the following sections, we discuss each of these and other steps which were omitted for clarity in greater detail.

\subsection*{Input genomes and pre-processing}
All annotated genomes in the genus \textit{Drosophila} available in April 2022 were downloaded from NCBI's RefSeq database. The assemblies annotated by the NCBI eukaryotic genome annotation pipeline have passed several quality checks and all have supporting transcript evidence, so the annotations are generally highly complete~\cite{Thibaud-Nissen2013}. The \textit{D. miranda} annotation was excluded due to its unusual karyotype~\cite{Dobzhansky1935}. Other annotations were excluded after preliminary clustering showed a deficiency in the number of orthologous groups containing those genomes, indicating their annotations were less complete (data not shown). The \textit{D. melanogaster} annotation was downloaded from FlyBase~\cite{Gramates2022}. In total, the input data consists of 33 genomes, which are listed in Table~\ref{stable:genomes}. Many genes have transcripts that differ only in their UTRs, and as a result there are many duplicate protein sequences in the annotations. Though not strictly necessary, we removed the duplicates in our pipeline, which greatly reduced the computational burden of later steps.

\subsection*{Extraction of best hits from BLAST output}
The protein sequences in each genome annotation were searched against each other in reciprocal pairs using BLAST, yielding a list of high-scoring segment pairs (HSPs) for each query-target pair~\cite{Camacho2009}. HSPs are local alignments, meaning they do not necessarily span the entire lengths of the query and target sequences. Consequently, the search algorithm may return multiple HSPs for each query-target pair if statistically significant regions of homology are separated by nonhomologous or poorly conserved regions. Though the most significant HSP is often used to represent all HSPs between a query-target pair, this approach can fail to rank the pairs by their overall significance if their alignments are broken into multiple HSPs. Furthermore, since query-target pairs were later filtered by the amount overlap between their sequences, it can also exclude pairs that pass the overlap threshold even if the most significant HSP alone does not. Thus, HSPs were merged into a single object called a hit. The best hits for each query were then taken as the highest-scoring hits that passed a minimum overlap criterion and were reciprocal between the query and target sequences.

\subsection*{Clustering in orthologous groups}
The best hits between sequences are naturally visualized as a graph where sequences are nodes and best hits are edges between nodes. Two connected components, sets of nodes joined by a sequence of edges, are shown (Fig.~\ref{fig:components}A,B). The sequences in the first (Fig.~\ref{fig:components}A) all contain C2H2 zinc fingers, whereas the sequences in the second (Fig.~\ref{fig:components}B) are members of the Par-1 family of serine/threonine protein kinases. In both components, some sets of nodes have a high density of edges, forming distinct clusters, whereas other nodes are only sparsely connected to their neighbors. To better understand the structure of these two components, we calculated the number of sequences, unique genes, and unique species in each. The first has 385, 346, and 33 sequences, genes, and species, respectively, and the second has 222, 33, and 33 sequences, genes, and species, respectively. We then plotted the relationship between the number sequences and unique genes across all components to see if this pattern holds true generally (Fig.~\ref{fig:components}C). Two distinct trendlines are apparent. The first increases linearly with the number of sequences with a slope of one, indicating each sequence is generally associated with a unique gene. The second is constant with an intercept of 33, indicating the number of unique genes quickly saturates at the total number of genomes. Thus, there are generally two classes of components. The first is composed of many distinct genes, whereas the second is composed of many different isoforms of a single group of genes.

The diffuse networks observed in the first component class are likely the result of a combination of factors, including rapid evolution, gene duplication, and annotation errors. Regardless of their origin, these hits are not strong candidates for comparative analyses since an orthology relationship is supported by relatively few genome pairs. Instead, likely orthologs should consistently identify each other as best reciprocal hits across many genome pairs. The same is true of the hits in the second component class. Although the genes as a unit form a single orthologous group, sequences with few hits are likely non-conserved or tissue-specific isoforms. Thus, orthologous groups can be operationally defined as self-consistent clusters in the hit graph. However, sequence divergence or assembly and annotation errors may prevent a best reciprocal hit between orthologous sequences across all genome pairs. In fact, although the most common number of reciprocal hits is 32, one fewer than the total number of genomes, many sequences have fewer (Fig.~\ref{fig:components}D). Thus, the clustering method should require a high degree of self-consistency without demanding complete consensus.

\begin{figure}[h!]
\includegraphics[width=\textwidth]{components/out/0017-005F.png}
\centering
\caption{\textbf{Selected connected components of hit graph and summary statistics.}
\textbf{(A-B)} Two distinct connected components of the hit graph. Edges are colored by the value of their bit score. \textbf{(C)} Hexbin plot of the number of sequences and the number of unique genes in each component. \textbf{(D)} Histogram of number edges associated with each sequence, \textit{i.e.} the degree of each node. Only the lower 99th percentile of the distribution is shown.}
\label{fig:components}
\end{figure}

The identification of sets of densely connected nodes in graphs is known as community detection in network analysis. While many community detection algorithms are available, only some are commonly used in the context of orthology inference. One early method that remains popular is building clusters progressively by identifying nodes that form a triangle with at least two other nodes in the cluster~\cite{Tatusov1997, Jensen2007}. Other approaches include the MCL algorithm, which clusters graphs by similating stochastic flow, and connected components or other single-linkage criteria~\cite{Remm2001, Enright2002, Li2003, Emms2015, Train2017, Cosentino2018}. While these methods are robust when clustering hit graphs derived from smaller or more diverse sets of genomes, they are not suitable for the large number of closely related genomes in this work since they require relatively few edges to define a cluster. For example, the MCL algorithm and connected components method assign a node to a cluster as long as it has a single edge, and triangle clustering only requires two edges to two adjacent nodes.

However, connected components and triangle clustering are special cases of the more general \textit{k}-clique percolation algorithm where \textit{k} equals two and three, respectively. The clique percolation algorithm detects clusters by first identifying cliques, sets of nodes which are fully connected, of a specified size \textit{k} in the graph (Fig.~\ref{fig:percolation}A). Clusters are then taken as the connected components of an overlap graph where an edge exists between two cliques if they share \textit{k}-1 nodes in common. An intuitive way to visualize this algorithm is by “rolling” a clique of some size \textit{k} over the graph (Fig.~\ref{fig:percolation}B). More specifically, a cluster is initiated when a set of nodes which form a \textit{k}-clique is identified. The cluster expands by shifting the \textit{k}-clique to an adjacent \textit{k}-clique that shares \textit{k}-1 nodes in common with the current \textit{k}-clique. A cluster stops expanding when there are no adjacent \textit{k}-cliques, and the algorithm terminates when there are no \textit{k}-cliques which are not part of a cluster. The strength of this algorithm is its ability to exclude sparsely connected nodes from clusters with an easily tunable parameter \textit{k}. Higher values of \textit{k} require greater overlap between a candidate node and those already in the cluster and therefore produce tighter clusters at the cost of excluding more speculative orthology relationships (Fig.~\ref{fig:percolation}C). We set \textit{k} to 4 as compromise between these concerns, yielding 22,813 orthologous groups, a plurality of which contained all 33 species (Fig.~\ref{sfig:clusters}).

\begin{figure}[h!]
\includegraphics[width=\textwidth]{percolation/percolation.png}
\includegraphics[width=\textwidth]{percolation/out/005F.png}
\centering
\caption{\textbf{Clique percolation algorithm.}
\textbf{(A)} Cliques for \textit{k} equal to three, four, five, and six. \textit{k} equal to one and two correspond to a single node and two nodes joined by an edge, respectively. \textbf{(B)} Illustration of clique percolation algorithm where \textit{k = 4}. \textbf{(C)} A single component clustered by clique percolation with varying values of \textit{k}. Nodes are colored according to their cluster. If a node belongs to multiple clusters, it uses a blend of those colors.}
\label{fig:percolation}
\end{figure}

\subsection*{Addition of paralogs to orthologous groups}
A weakness of the best reciprocal hits criterion is its exclusion of recently diverged paralogs. Since only the highest scoring hits for each query are included in the graph, a paralog without a corresponding duplicate in the target genome is ignored if it is marginally more diverged than the other copy. This is corrected by adding likely paralogs to the orthologous groups. Briefly, the protein sequences in each genome were searched against themselves. If the bit score for an intra-genome hit exceeded the bit score of any inter-genome hits for the same query, the two sequences were identified as a paralogous pair. Orthologous groups were then supplemented with paralogs by adding the paired sequences for each of the original members of the orthologous group. Most orthologous groups contain no paralogs, and those that do generally have few relative to the original number of sequences in the group (Fig.~\ref{sfig:paralogs}).

\subsection*{Grouping orthologous groups by gene}
As genes can have several annotated isoforms, each gene can be associated with several orthologous groups. However, the orthologous groups are not organized into gene-level units since they were clustered using sequence similarity only. A graph-based approach was therefore used to group orthologous groups with similar sets of parent genes. First, a gene overlap graph was constructed by defining an edge between orthologous groups if the intersection of their associated sets of parent genes is at least 50\% of the smaller of the two. Gene groups were then taken as the connected components of the resulting graph, yielding 14,909 groups. This is commensurate with the roughly 15,000 genes in each genome, which suggests this approach has successfully clustered orthologous groups derived from a common set of parent genes.

\subsection*{Initial alignment and selection of representative sequences}
Since the NCBI annotation pipeline incorporates transcriptome data from a variety of sources, its inputs are heterogeneous in sequencing depth, developmental stage, and tissue of origin across different genomes. As a result, some genomes are annotated with different or multiple splice isoforms of a given orthologous gene, which can create complex networks in the resulting hit graph. For example, if the genomes are variably annotated with one or both of two distinct isoforms, the resulting graph may contain two clusters connected by a ``bridge'' formed by the genomes which contain only one of the isoforms. If the nodes bridging the two clusters form cliques with themselves and the clusters, the clique percolation algorithm will merge all the nodes into a single orthologous group where some genes have multiple associated sequences. However, these additional sequences can complicate downstream comparative analyses that may not easily generalize to genes with multiple associated sequences. Thus, in our pipeline a single representative was chosen for each gene using an alignment-based strategy detailed in the methods section.

\subsection*{Selection of single copy orthologous groups}
The criteria for selecting orthologous groups for further analyses depends on the biological question under investigation. For example, studies of gene duplication will focus on orthologous groups with paralogs in some lineages but not in others. In contrast, analyses which assume functional conservation should restrict the orthologous groups to single copy orthologs since paralogs more frequently undergo functional divergence~\cite{Altenhoff2012, Pegueroles2013, Soria2014}. A simple method for identifying such groups is requiring each species to have exactly one associated gene. However, since the probability of at least one missing gene annotation approaches one as the total number of genomes increases, this is too restrictive and fails to leverage the redundancy of closely related genomes. Instead, a set of phylogenetic diversity criteria detailed in Table~\ref{stable:diversity_criteria} were applied to ensure the major lineages were represented in downstream analyses. Furthermore, genome-wide analyses should select one orthologous group per each of the previously identified gene groups as to not bias the results towards genes with many distinct groups of isoforms. In summary, orthologous groups failing the phylogenetic diversity criteria were first removed, and the representative for each gene group was chosen as the highest scoring orthologous group when ranked by the number species and the sum of the bit scores associated with each edge. This significantly reduced the number of orthologous groups from 22,813 to 8,566.

\subsection*{Alignment refinement}
An initial alignment was created for each orthologous group as part of the selection of representative sequences. Though the pipeline’s quality control measures ensure a high degree of overall sequence identity between members of an orthologous group, some sequences contain long “poorly supported” segments which are not aligned to most or any other sequences in the alignment. Since most common multiple sequence alignment algorithms assume the sequences are largely homologous, these segments are sometimes “over-aligned” by forcing them into alignment where chance sequence similarities occur. Typically, these segments remain contiguous, so the alignments alternate between short runs of columns with few or no gaps and large gap-rich regions. More rarely, when long poorly supported segments are adjacent to a long gap in the same sequence, the two are interlaced, yielding long gaps interrupted by short segments of spurious alignment.

The aligner MAFFT has a mode for addressing over-alignment with a parameter, \textit{a\textsubscript{max}}, that adjusts the strength of the correction~\cite{Katoh2013, Katoh2016}. \textit{a\textsubscript{max}} varies between 0 and 1, but at values above 0.8, the correction severely degrades the alignment of conserved regions. Thus, in our pipeline the sequences were aligned with a conservative value of 0.4. Though some cases of over-alignment remained, most conserved regions were reliably aligned with few to no errors. To correct the remaining errors in alignments of the single copy orthologs, a statistical model of each alignment called a profile HMM was constructed from the well-aligned columns~\cite{Eddy2009}. The original sequences were then aligned to these profiles. By defining highly conserved “anchor” regions, this approach largely prevents the alignment of chance sequence similarities in long poorly supported segments. Furthermore, since profile HMMs explicitly model the beginnings and ends of alignments, they can fully exclude these segments from the termini. This effect is visible in the illustrated examples, where each has long poorly supported segments that are completely removed (Fig.~\ref{fig:realignment}).

\begin{figure}[h!]
\includegraphics[width=\textwidth]{realignment/out/merged.png}
\centering
\caption{\textbf{Alignment with long poorly supported segments.}
The alignments of representative sequences in orthologous groups 23D9 \textbf{(A)}, 01E0 \textbf{(B)}, and 07C3 \textbf{(C)} before and after refinement.}
\label{fig:realignment}
\end{figure}

\subsection*{Alignment curation}
Although the refinement process corrects most cases of over-alignment, the alignment may still contain regions whose aligned segments have poor or inconsistent support. For example, long poorly supported segments in internal regions were not removed from the alignment since they are bounded by at least one consensus column to the left and right. Additionally, some regions have a significant fraction of sequences with strongly supported segments, but the observed gap pattern is discordant with the expected phylogenetic relationships. Since they are present in so few sequences, the former segments are likely artifactual, resulting from errors during assembly or annotation. (Biological explanations such as alternative splice sites, frameshift mutations, or transposition events are also possible, however.) In contrast, the high sequence identity and clear boundaries of the segments in the latter regions suggest they are conserved but skipped exons. Given the heterogeneous sourcing of the transcript evidence, these sequences containing these segments are likely splice isoforms specific to certain tissues or developmental stage.

% To investigate these hypotheses, the genome sequences and supporting transcript evidence for several segments and regions were examined in detail: 0254, 26CF, 202C, 188E, 2E9F, 34B7, 0C31.

Since the segments in these regions are likely the result of incorrect or incomplete annotations rather than meaningful biological variation, maintaining them in the alignments would propagate spurious homologies to subsequent analyses. This is a common issue in alignments generated by automated pipelines, so downstream analyses often focus on the strongly supported regions by removing or “trimming” columns below some threshold number of gaps or sequence identity~\cite{Castresana2000, CapellaGutierrez2009}. This approach, however, is inadequate if the taxonomic sampling is dense, as a single indel event along a lineage containing many species can increase the number of gaps above the threshold. Moreover, as this method does not incorporate any spatial information, it can rapidly alternate between trimming and preserving columns. Thus, it can severely disrupt any analyses which are sensitive to the spatial organization of an alignment.

Phylogenetic HMMs (phylo-HMMs) are statistical models that incorporate phylogenetic and spatial information to calculate the probability that each observation in a sequence was generated by one of several “hidden states”~\cite{Felsenstein1996}. Since they can evaluate both the probability of a gap pattern in a column given the known phylogenetic relationships and the local context, a phylo-HMM was used to segment the alignment into contiguous regions with different patterns of gaps. A fully specified phylo-HMM requires a fixed number of hidden states and a probability distribution for each. Thus, we identified four distinct types of regions in the alignments, roughly corresponding to highly conserved regions with few to no gaps, divergent regions, regions with a stable gap pattern discordant with the expected phylogenetic relationships, and regions with poorly supported segments. For simplicity, however, we refer to the states that generate each type of region as 1A, 1B, 2, and 3, respectively. To model probability distributions for each state, we first conceptualized the observed alignments as the superposition of two distinct processes (Fig.~\ref{fig:hmm}A, left). The first is a phylogenetic process which evolves and splits a single ancestral sequence over time according to a tree. The second is the annotation process which can erroneously exclude or include segments from a sequence. The result is an alignment of annotated sequences which contains evolutionary information obscured by ``noise'' from the annotation process, shown here by the exclusion of three N-terminal residues in the fourth annotated sequence. To simplify modeling this behavior with an HMM, we coded the sequences into binary symbols. The distributions for each state then consisted of two components derived from the encoded sequences (Fig.~\ref{fig:hmm}A, right). The first component models the gap pattern with a Markov process. This Markov process is in turn composed of two subprocesses where the first is a phylogenetic process, and the second is a jump process. These subprocess roughly correspond to changes caused by evolution and annotation, respectively. Because this first component did not fully capture the propensity for the gap patterns to remain constant, we included a second component that models the ``gap stickiness'' as a beta-binomial random variable by counting the number of symbols that remain constant between columns. Each component is associated with a set of parameters, and the unique parameters for each state yield its characteristic gap pattern and gap stickiness.

After the model was trained on manually labeled examples, it was used to assign a label to the columns in each alignment. Columns assigned to states 1A and 1B are the regions of interest for downstream analyses since the gaps generally follow the expected pattern given the phylogenetic tree. In contrast, columns assigned to states 2 and 3 largely corresponded to the long poorly supported segments and phylogenetically discordant regions discussed previously and were therefore removed from the alignments. In the example decoded alignment shown, the decoded states closely follow the expected patterns (Fig.~ref{fig:hmm})B). Overall, fewer than 10\% of alignments were trimmed of any regions. However, when regions were trimmed, they were largely inferred as state 3, meaning the removed regions are generally long poorly supported segments that are aligned to few if any other sequences (Fig.~\ref{sfig:hmm_trim}).

\begin{figure}[h!]
\includegraphics[width=\textwidth]{hmm/hmm_architecture.png}
\includegraphics[width=\textwidth]{hmm/out/2252.png}
\centering
\caption{\textbf{HMM emission architecture and a decoded alignment.}
\textbf{(A)} Schematic of theoretical alignment generating process and corresponding probabilistic components in HMM. White and colored boxes indicate gap and non-gap symbols in the biological sequences, respectively. White and grey boxes indicate gap and non-gap symbols in the encoded sequences, respectively. c\textsubscript{0} and c\textsubscript{1} indicate the first and second columns in the alignment, respectively. The parameters associated with each component are shown to the right. \textbf{(B)} The alignment of the representative sequences in orthologous group 2252 decoded using the trained HMM.}
\label{fig:hmm}
\end{figure}

Though the phylo-HMM removed phylogenetically incongruent ``insertions,'' some sequences still contained extensive segments of uninterrupted gaps. These segments are easily identified in regions which are otherwise highly conserved, so they are also likely the result of incorrect or incomplete annotations. Unfortunately, they can also span more divergent regions, which complicates a simple rule- or threshold-based approach for identifying them. Thus, another phylo-HMM was trained to label each position in a sequence as generated by either a ``missing'' or ``not missing'' state. In this case, however, the aligned sequences were processed individually and not as aligned columns. As the previous phylo-HMM already ensured each column has sufficient support, these labels can instead be used to exclude sequences from downstream analyses depending on the amount of tolerated overlap with the regions of interest.

\subsection*{Inference of species trees}
Many phylogenetic methods require a species tree to inform the evolutionary relationships between sequences. In fact, the phylo-HMMs discussed previously used a species tree as an input, though we omitted this detail for clarity of exposition. Therefore, to support the curation step and other downstream analyses, we sought to infer phylogenetic trees from the aligned sequences. However, since the roots of phylogenetic trees are not identifiable with commonly used time-reversible substitution models, we repeated the orthology inference pipeline with the outgroup species \textit{Scaptodrosophila lebanonensis}. Afterwards, we inferred phylogenetic trees using the LG model of amino acid substitution from 100 meta-alignments sampled from alignments of single copy orthologous groups. We then combined them into a single consensus tree (Fig.~\ref{fig:trees}A). To provide a similar tree for the analysis of non-coding regions, we inferred phylogenetic trees using the GTR model of nucleotide substitution from 100 meta-alignments sampled from nucleotide alignments which were ``reverse translated'' from the protein alignments and their corresponding coding sequences (\ref{fig:trees}B). Both trees have an identical topology, which is consistent with other published phylogenies~\cite{D12GC2007, DaLage2007}.

\begin{figure}[h!]
\includegraphics[width=\textwidth]{trees/out/trees1.png}
\centering
\caption{\textbf{Phylogenetic tree of species.}
\textbf{(A)} Consensus tree from LG model fit to meta-alignments directly sampled from the original protein alignments. \textbf{(B)} Consensus tree from GTR model fit to meta-alignments sampled from ``reverse translated'' nucleotide alignments. Values at nodes are bootstrap percentages.}
\label{fig:trees}
\end{figure}

\section*{Discussion}
The orthologous groups and alignments yielded by this pipeline are a valuable resource for comparative studies of gene birth/death processes and protein evolution at the level of both entire proteomes and specific gene families in the \textit{Drosophila} genus. To assist these efforts, the final alignments after curation and the labels from the ``missing'' phylo-HMM are provided as supplemental data. Although this work focused on single copy orthologs, other studies may require different subsets of orthologous groups that demand other pre-processing and alignment strategies. Therefore, we have included the orthologous groups and the initial alignments with and without non-representative sequences in the supplemental data as well. While we anticipate these resources will remain relevant in the near term, the trends that permitted this work to substantially improve on previous efforts will render them obsolete in the coming years as more \textit{Drosophila} genomes are assembled and annotated. However, an authoritative and lasting set of orthologous groups and alignments is not the primary goal of this work. Instead, it serves as a case study in how dense taxonomic sampling and modern genome assembly and annotation pipelines present new opportunities and challenges to the traditional techniques for identifying and aligning orthologous groups.

For example, despite many additional pre-processing steps and other tweaks introduced by later authors, the basic framework of orthology inference by clustering the hit graph has remained largely unchanged in the past twenty years~\cite{Tatusov1997, Remm2001, Li2003, Jensen2007, Linard2011, Emms2015, Train2017, Cosentino2018}. This longevity is a testament to the robustness of the underlying idea that orthologous proteins should consistently identify each other as the most similar pairs between their genomes. Even as the number of genomes and their taxonomic density has increased dramatically, many orthology inference pipelines continue to use algorithms which were originally applied to sets of far fewer and more distantly related genomes. This mismatch in scale increases the chance of propagating annotation errors since only a small number of edges are needed to create or merge clusters. Thus, we instead applied a generalization of the triangle and connected components clustering methods called \textit{k}-clique percolation where \textit{k} is a tunable parameter that influences the tightness of a cluster. The optimal value of \textit{k} for a given set of genomes is unclear and likely depends on the desired trade-off between sensitivity and specificity. Furthermore, \textit{k} is not necessarily a global parameter and can instead depend on the properties of each connected component. For example, one possibility is to take an entire component as an orthologous group if its number of unique genes and unique species are equal since all the sequences are isoforms of a single set of genes. This would effectively set \text{k} equal to one for this component. Another approach is to make \textit{k} an decreasing function of the density of edges, so sparser graphs are clustered more permissively. However, percolation theory or simulations may yield additional insights.

Another challenge is the annotation of multiple isoforms for a single gene. Though prior pipelines have generally selected the longest isoform as the representative before conducting the orthology searches, if the sequences do not share a common intron-exon structure this approach can introduce artifacts or other issues during alignment. Instead, as protein sequences are increasingly derived from or linked to genomic sequences, we sought to incorporate the full annotations into the orthology inference pipeline. This, however, created two additional complications. First, a single gene could have several associated orthologous groups if its isoforms belonged to different clusters. Second, a single orthologous group could have several isoforms of a single gene if its isoforms were clustered together. In both cases, the presence of multiple sequences for a single gene creates ambiguities over which is the “primary” isoform. Since the first occurs at the level of orthologous groups, the orthologous groups were first grouped by the similarity of their parent genes using a graph-based strategy. Afterwards, a single representative is easily chosen as the group with the largest number of distinct species, though other criteria are possible. Since the second occurs within an orthologous group, the sequences were first aligned, and a representative for each gene was chosen as the sequence which was most concordant with this initial alignment.

The second major innovation in this work is its method for the refinement and trimming of alignments. In refinement, a profile HMM is constructed from the well-aligned columns of an initial alignment, and the original sequences are aligned to this profile. This process usually corrects errors caused by the presence of long poorly supported segments. In trimming, a phylo-HMM is used to remove regions and segments which are poorly supported by the phylogenetic consensus. While the combination of these two steps yielded high-quality alignments that are suitable for further analyses, they are an \textit{ad hoc} fix for underlying issues with the gene models and alignment algorithms. The most principled solution is to optimize or supplement the gene models using the initial alignments generated by the orthology inference pipeline, which is possible with tools such as OMGene or OrthoFiller~\cite{Dunne2018, Dunne2017}. However, if preserving the original annotations is desired or necessary, the remaining possibility is to correct the alignments as we have done here. In fact, the errors we sought to address broadly stem from shortcomings of current alignment algorithms rather than errors in the sequences themselves. Though the scoring functions of modern multiple sequence alignment algorithms are complex, they are generally derived from models that penalize gaps with a linear or affine cost. As a result, they often interlace gaps with short, aligned segments rather than a single long gap. However, when the sequences are different isoforms of a single gene, their alignment will necessarily contain contiguous exon sized gaps. The same is true when aligning isoforms of diverged orthologs, though the relationship between their exons may be complex.

The most popular aligners for protein sequences (Clustal Omega, MAFFT, MUSCLE, T-Coffee) do not include splice sites in their alignments, which makes them prone to aligning non-homologous exons~\cite{Sievers2017, Katoh2013, Edgar2004, Notredame2000}. Current algorithms can easily be extended to incorporate splice sites by coding them as a new symbol and preventing alignment between splice sites and amino acids, which was recently implemented in the aligner, \textit{Mirage}~\cite{Nord2018}. The biggest challenge in practice, however, is mapping a protein sequence to its genomic sequence to identify splice sites in the protein sequence. Although this information can in principle be derived from the GTF annotation files produced by the NCBI pipeline, annotating the splice junctions in the protein sequences themselves would facilitate splice-sensitive alignment.

These improvements would enhance rather than replace the phylo-HMM trimming method developed in this work. The model could easily be extended to include a state that outputs a splice symbol before transitioning to one of the states in the current architecture. This intermediate state would increase the accuracy of state inference since a splice symbol followed by a phylogenetically discordant gap pattern would strongly signal a state 2 region. The association between state 2 and skipped exons can be made explicit by requiring that transitions to and from state 2 first proceed through the splice state. This of course depends on proper labeling of the training data, which would be trivial since the boundaries between exons would be marked by splice site symbols rather than inferred from gap patterns. Unfortunately, this would not allow the phylo-HMM to label extended exon boundaries as state 2 since they would not be bounded by splice symbols to the left and right. Accordingly, the phylo-HMM would need to permit transitions between state 3 and any other state to accommodate more complex splice variants and other annotation errors. Thus, this extended phylo-HMM would combine the strengths of splice-sensitive alignment with the more heuristic approach used here. Since state 2 inferences would necessarily correspond to skipped exons, they would be suitable for analyses of this form of alternative splicing. Though state 3 inferences would not directly correspond to specific biological process, they still have value as spatially and phylogenetically aware labels for trimming poorly supported segments from alignments.

The phylo-HMM could be further enhanced by expanding its emission distribution to include more symbols in the amino acid alphabet. This would allow it to better model observed substitution patterns between specific symbols, for example the high rate of exchange between gaps and glutamine residues caused by polyglutamine tracts. The transitions between amino acids could be parametrized with a published matrix such as LG~\cite{Le2008}, but the transitions between amino acids and gaps would be inferred from labeled data. It is unclear if the resulting gain in accuracy would justify the increased computational burden, however.

Though there are benchmarks available for optimizing and comparing methods of orthology inference, the metrics are calculated over a set of reference genomes which are sparsely sampled over a broad taxonomic range, so it is unclear if they are informative for method designed to yield robust inferences when the genomes are highly related~\cite{Nevers2022}. Furthermore, the heterogeneity of genome architectures and annotations may require quality assurance methods tailored to each set of genomes. Thus, there is likely no one-size-fits-all approach to orthology inference, and with many other standalone programs available for more standard use cases (Hieranoid, OMA standalone, OrthoFinder, OrthoInspector, Orthologer), we have chosen not to package the code into an end-to-end pipeline~\cite{Kaduk2017, Altenhoff2019, Emms2019, Linard2014, Zdobnov2020}. Instead, we have devoted considerable attention to organizing and documenting the code to make it accessible to a newcomer and thereby facilitate the adaptation of specific steps to similar projects as needed.

In contrast, though many HMM packages are available for the Python programming language, we found none were satisfactorily documented or contained tutorials to introduce HMMs and their APIs to a wide audience. We therefore refactored this code into a package available on PyPI and GitHub called Homomorph. The package itself only implements standard HMM algorithms, but the GitHub repository includes tutorials that introduce the API and implement training routines. Similar tutorials for machine learning libraries such as TensorFlow have undoubtedly fueled the application of neural networks across diverse fields, but HMMs are also powerful models that can be more appropriate when the data obey certain statistical or structural constraints. Thus, we hope this package and its accompanying tutorials will serve as an on-ramp to HMMs and spur their greater adoption by non-specialists.

Though databases of orthologous groups such as COGs, Ensembl Compara, EggNOG, OMA, OrthoDB, OrthoInspector, and OrthoMCL will continue to be useful for comparative studies across broad taxonomic ranges, the increasing speed at which high-quality genome assemblies and annotations are produced means no single database can encompass the most complete data~\cite{Galperin2020, Herrero2016, HuertaCepas2018, Altenhoff2020, Zdobnov2020, Nevers2018, Chen2006}. Furthermore, since many early comparative genomics studies spanned diverse branches of the tree of life, future research will likely prioritize taxonomic depth over breadth. Thus, custom sets of orthologous groups will grow more and not less common. Despite the challenges these developments pose, they also present new opportunities to bridge the gap between mutational and macroevolutionary processes.

\section*{Materials and methods}
\subsection*{Sequence de-duplication and BLAST search parameters}
The protein sequences for each annotation were de-duplicated by removing any sequences which had already appeared in association with the same gene. Thus, the first accession associated with a sequence and gene pair is the sequence’s representative accession for the gene. BLAST+ 2.13.0 was used for the sequence similarity searches~\cite{Camacho2009}. An E-value cutoff of 1 was used for the initial searches. However, this cutoff was lowered to 1E-10 during processing of the BLAST output.

\subsection*{Extraction of HSPs from BLAST output}
To reduce the computational burden of merging HSPs into hits, the BLAST output was filtered to extract HSPs associated with the highest-scoring gene. The HSPs were first grouped by target protein, and the resulting groups were sorted in descending order by the bit score of their highest-scoring HSP. Iterating over the groups, all the HSPs in a group were passed to the next step until the parent gene of the group was not the parent gene of the highest ranked group. This method collects all candidate HSPs for a target gene if the highest-scoring HSP within a group exceeds the highest-scoring HSP of the next best gene. This is in some senses an extension of the best hit criterion where hits are considered at the level of genes rather than proteins. If multiple genes tied for the highest-scoring HSP, the iteration stopped when the parent gene of the current group matched none of these highest-scoring genes.

\subsection*{Merging of HSPs into hits}
HSPs were merged in two stages where the first combined non-overlapping HSPs, and the second combined the remaining HSPs. In the first stage, proceeding from highest to lowest bit score, HSPs were marked as “disjoint” if they do not overlap with any other HSP previously marked as disjoint. Although this greedy strategy does not necessarily yield the highest-scoring set of disjoint HSPs, it prioritized higher scoring HSPs. In the second stage, all disjoint HSPs were marked as “compatible,” and proceeding from highest to lowest bit score the remaining HSPs were marked as compatible if the overlap with any other compatible HSP was no more than 50\% of the length of either. The best hit for each query was chosen as the hit with the highest sum of bit scores from disjoint HSPs. The best hits were then filtered by overlap and reciprocity criteria. The overlap criterion was applied first and requires that 50\% of residues in the query are aligned in compatible HSPs. This excludes false positives from conserved domains embedded in larger non-homologous proteins by ensuring the hits span a sufficient fraction of the query and target sequences. The reciprocity criterion requires each query-target pair has a corresponding hit where the roles are reversed, which ensures there is no ambiguity in which target is the best match for the query.

\subsection*{Clustering by \textit{k}-clique percolation}
\textit{k}-clique percolation was implemented in two steps. In the first, maximal cliques were identified. In the second, a percolation graph is constructed by defining edges between cliques if they have \textit{k}-1 nodes in common. Clusters are the connected components of this second graph. The first step uses the NetworkX implementation of a maximal clique algorithm. The second step uses a modification of the NetworkX implementation of the \textit{k}-clique community algorithm. The NetworkX implementation exhaustively finds all edges in the percolation graph. Since joining a \textit{k}-clique community only requires that a clique has a single edge connecting it to that a community, this approach is needlessly expensive for large graphs. The custom implementation instead uses a progressive approach where each clique is checked against a list of known communities, merging communities as necessary in each step.

The hit graph is sparse, so these algorithms are efficient when applied to its individual connected components. However, some components have a structure with many maximal cliques, which dramatically slows the first or second step of the clique percolation algorithm. Thus, if either step exceeded 90 s, the process timed out, and the simpler \textit{k}-core algorithm was used instead. Out of over 10,000 connected components, only seven timed out, and many of those contained highly dense clusters of histone sequences.

\subsection*{Addition of paralogs to orthologous groups}
The protein sequences for each annotation were searched against themselves with the same settings as for the inter-genome searches. The resulting output was processed identically except the HSPs were not filtered using the best gene criterion. Thus, all HSPs for each query were merged into hits. The best hit for each query and target gene was then chosen as the hit with the highest sum of bit scores from disjoint HSPs. (Grouping by target gene ensured only the highest-scoring isoform was selected.) Query-target pairs whose hits which exceeded the maximum bit score for all inter-genome hits associated with that query and passed the overlap and reciprocity filters were designated as paralogous pairs. The orthologous groups were supplemented with paralogs by adding the paired sequences for each of the original members of the orthologous group.

\subsection*{Initial alignment and selection of representative sequences}
The sequences in each orthologous group were aligned using MAFFT 7.490 with the following settings: -{}-globalpair -{}-maxiterate 1000 -{}-thread 1 -{}-anysymbol -{}-allowshift -{}-leavegappyregion -{}-unalignlevel 0.4~\cite{Katoh2013}. Representative sequences for each gene were then selected by maximum likelihood according to binary profiles constructed from these alignments. First each sequence was coded into gap and non-gap symbols. The sequences were then grouped by gene, and for each group and position if at least one sequence was aligned in the group, the group contributed one count for the non-gap symbol to the profile at that position. Otherwise, the group contributed a count for the gap symbol at that position. To account for the phylogenetic dependencies between sequences, the counts were weighted according to a Gaussian process over the GTR2 consensus tree described in the section on inferring species trees~\cite{Altschul1989}. If a species had multiple genes in the orthologous group, the species weight was divided evenly among them. Each coded sequence was then scored according to this profile, and the maximum likelihood sequence for each gene was selected as its representative. By assigning a non-gap count to groups and positions where at least one sequence is aligned, the profile incentivizes the selection of sequences contain the fewest gaps and match the consensus alignment. Unfortunately, this scheme can cause a sequence to score negative infinity if it has a gap at a position where every group has at least one aligned sequence, so the profile was initialized with a pseudocount of 0.005 for the gap and non-gap symbols at each position.

\subsection*{Alignment refinement}
Consensus columns were manually defined as columns in the initial alignments with at least five non-gap symbols using the Stockholm file format. These labeled alignments were used to build a profile HMM using HMMer 3.3.2~\cite{Eddy2009}. No sequence relative weighting was used, and the effective number of sequences was set to three times the number of sequences in the alignment. HMMer uses strong priors to allow the construction of profiles with relatively few aligned sequences. However, in rare cases a sequence with a long poorly supported segment was misaligned, effectively putting it out of register with the profile and creating a poor-quality alignment. Increasing the effective sequence number corrected this error. The original sequences were then aligned to the profile. Unaligned segments at the N- or C- terminus were removed from the alignment. Unaligned segments in internal regions were extracted and aligned separately for each region using MAFFT with the same settings. The resulting alignments were then “stitched” into the profile alignment. This process was unsuccessful for one alignment due to cryptic error in MAFFT, which reduced the number of refined alignments to 8,565.

This method corrects most cases of misalignment since poorly supported segments are typically aligned to fewer than four other sequences. However, it does not remove poorly supported segments from columns with more than five non-gap symbols, and their contribution is sometimes sufficient to reproduce the misalignment when the sequences are aligned to the profile HMM. A lightweight convolutional neural network was therefore trained to recognize poorly supported segments to remove them more completely from the profile HMM. The network consisted of a two-dimensional embedding from a 22-dimensional one-hot-encoded vector (20 amino acids, an ambiguous amino acid, and a gap), two convolutional layers, and a one-dimensional output. The first layer was composed of four filters. Two of these filters had a kernel size of 10 and a dilation of 1. The other two filters had a kernel size of 60 with a dilation of 3. The second layer was composed of two filters with a kernel size of 10 and a dilation of 1 (Fig.~\ref{sfig:cnn_architecture}). The network was trained on 88,513 hand-labeled positions across 122 sequences in 46 unique alignments. These examples were largely long segments aligned to few, if any, other sequences (Fig.~\ref{sfig:cnn_training}).

The trained network outputs a probability that each position in an aligned sequence is part of a long poorly supported segment. A simple algorithm was used to detect positions associated with high confidence long poorly supported segments even if the output at that position was relatively low. First, “seeds” were identified at positions where the output exceeded 0.75. These seeds were expanded outwards until the output was below 0.05. A seed and its expansion composed a long poorly supported segment. Consensus columns were defined as columns with at least five non-gap symbols, excluding positions labeled as long poorly supported segments. To maintain the contribution of long poorly supported segments to the profile’s models of insertions, long poorly supported segments were replaced with gaps only at positions aligned to consensus columns.

\subsection*{Alignment curation}
The alignments were coded into gap and non-gap symbols to simplify the emission distributions. The ``insertion'' phylo-HMM was composed of the four hidden states described in the main text. The emission distributions for each consisted of two components which modeled the gap pattern and the propensity for those patterns to remain constant (``gap stickiness''), respectively. The first component was a two-state Markov process which was in turn composed of two subprocess. The first was a phylogenetic process on the on the GTR2 consensus tree described in the section on inferring species trees, and the second was jump process at the tips. The second component was a beta-Bernoulli distribution on the number of symbols which were constant between subsequent columns. The ``missing data'' phylo-HMM was composed of two hidden states which were both parameterized with the same two-state, two component Markov process as the insertion phylo-HMM. However, the emission probabilities were calculated as the posterior probability of the observed symbol given the data rather than the probability of the data. Only the alignments of the single copy orthologous groups were curated, so each tip in the species tree would correspond to a single sequence in the alignment.

All HMM algorithms were implemented with custom code which is available as the package Homomorph on PyPI. The insertion phylo-HMM was trained on 39,298 manually labeled columns in 11 alignments, and the deletion phylo-HMM was trained on 58,655 manually labeled positions in 20 sequences in 9 unique alignments (Fig.~\ref{sfig:hmm_training}). Because maximum-likelihood estimation of the model parameters yielded posterior decoding curves which toggled between hidden states too rapidly, the models were instead trained discriminatively~\cite{Krogh1999}. The difference, briefly, is maximum-likelihood estimation finds the parameters that best reproduce the observed distributions whereas discriminative training finds the parameters that minimize prediction error. Discriminatively trained models typically perform better in practice since real-world data are rarely fully described by the distribution specified by the model.

The posterior distributions over states were computed for both the insertion and missing data phylo-HMMs. To trim the alignments, the posterior distributions from the insertion phylo-HMM were converted to state assignments with the following method. First the probabilities for states 2 and 3 were combined. Since this probability can change rapidly or gradually depending on the local context, a simple cutoff would not necessarily define the boundaries as the columns where the gap pattern changes most abruptly. Instead, a high cutoff of 0.9 was used to define a “seed” region. The boundaries of the seed were then expanded both inwards and outwards to define intervals from which to select boundaries. The outward expansion halted when the probability or its derivative was below 0.05 and 0.001, respectively. The inward expansion halted when the derivative was below 0.02. The left and right boundaries were chosen as the columns in each expansion with the maximum product between the derivative and the number of sequences which changed to or from a gap between columns. By combining where the model’s confidence changed rapidly with the observed change in the gap pattern, this method generally selected reasonable boundaries. In contrast, the posterior probabilities from the missing data phylo-HMM changed sharply, so positions were labeled as the ``missing data'' state if the posterior probability exceeded 0.95. These assignments can be used to filter segments or entire sequences from downstream analyses and are available in the supplementary data.

\subsection*{Inference of species trees}
The orthology inference pipeline was first repeated with the outgroup species \textit{Scaptodrosophila lebanonensis}. Then orthologous groups with one sequence for each species were aligned, and 100 meta-alignments were constructed by randomly sampling 10,000 columns from these 9,435 alignments. (The alignments were not refined with HMMer before sampling.) To determine the effect of invariant columns and gaps, two sampling strategies were used where invariant columns were allowed or disallowed and the maximum fraction of gaps was set at 0, 50, and 100\%. Their combination yielded six different sets of meta-alignments. A tree was fit to each meta-alignment with the LG substitution model and four discrete gamma rate categories using IQ-TREE 1.6.12~\cite{Nguyen2014, Le2008, Yang1994}. If the sampling strategy allowed invariant columns, an invariant rate category was included. The resulting trees from each set were then merged into a majority consensus tree (Fig.~\ref{sfig:trees_LG}).

To fit trees using the GTR model of nucleotide substitution, the protein alignments were converted to nucleotide alignments using the corresponding coding sequences in the genome annotations. Some protein sequences are “low quality,” meaning their coding sequences contain frameshifts, premature stop codons, or other errors even though they are strong hits to known protein-coding genes. The NCBI annotation pipeline corrects some of these defects in the protein sequences, which can complicate a simple “reverse translation” of the alignment. After rejecting alignments where the expected translation from a coding sequence differed from its corresponding protein sequence, 3,425 alignments remained. Consensus tree were derived from meta-alignments sampled from these alignments using the approach described previously except the GTR model was used in place of the LG model.

To fit trees using the two-state GTR model of substitution, the protein alignments were first coded into gap or non-gap symbols. As before, 100 meta-alignments were constructed from these coded alignments for each sampling strategy. In this case, only the presence of invariant columns was varied, yielding two sets of meta-alignments. Trees were then fit using the GTR2 model with no rate categories. An invariant category, however, was included if invariant columns were allowed. Since the bootstrap confidences were sometimes lower than 50\%, the resulting trees from each set were then merged into a loose consensus tree to prevent multifurcations (Fig.~\ref{sfig:trees_GTR}).

\subsection*{Code and data availability}
\begin{sloppypar}
The code used to produce the results and analyses is available at \url{https://github.com/marcsingleton/orthology_inference2023}. HMM algorithms were implemented in the standalone package Homomorph which is available at \url{https://github.com/marcsingleton/homomorph} and on the Python Package Index (PyPI). The following Python libraries were used: matplotlib, NumPy, pandas, SciPy, and TensorFlow~\cite{Hunter2007, Harris2020, McKinney2010, Virtanen2020, Abadi2015}. Relevant output files are available in the supporting information. There is no primary data associated with this manuscript. All primary data are available from publicly accessible sources described in their corresponding sections.
\end{sloppypar}

\begin{abstract}
\noindent
Fitting statistical models to data is often a key step in the scientific method because it can formalize hypotheses and conclusions as unambiguous and testable statements. The major scientific computing library for the programming language Python, SciPy, provides ready-to-use implementations of core statistical functions, which allows users with varying levels of expertise to easily apply them to their data. However, SciPy does not support two common and powerful types of models called mixture models and hidden Markov models (HMMs). Other more specialized packages such as hmm-learn and pomegranate provide implementations for a restricted subset of these models, but they use APIs which are not compatible with SciPy. This can pose a barrier to entry for beginners and prevent more advanced users from easily extending these packages' capabilities. We therefore created two packages, MixMod and Homomorph, that implement mixture models and HMMs, respectively, and conform to the SciPy API for specifying distributions. Each package is fully documented, and we wrote a set of tutorials which both introduce their APIs and illustrate various training techniques through a series of examples. These packages are available on the Python Package Index (PyPI) under the names mixmod and homomorph, and the source code is hosted alongside the tutorials on GitHub at \url{https://github.com/marcsingleton/mixmod} and \url{https://github.com/marcsingleton/homomorph}, respectively.
\end{abstract}

\section{Overview of tools and tutorials}
Most code written for data analysis is \textit{ad hoc}, that is, it is intended to accomplish a single task and cannot be used for any other purpose. However, often solving one problem entails solving several other problems along the way, and sometimes those intermediate solutions are general enough to be widely useful. This happened twice over the course of this work, both times involving fitting probabilistic models to data. The first was mixture models, which describe data that contain several subpopulations, each with its own statistical properties, mixed together. For example, in exam scores there are often two clusters: the high-scoring group of students who understood the material and the low-scoring group who did not. The second was hidden Markov models (HMMs), which like mixture models, describe data with several subpopulations. However, in HMMs the data are ordered in a time series and observations from a given subpopulation tend to occur consecutively. These models are frequently used to analyze systems which toggle between different states over time, for example periods of growth and recession in the economy.

Both types of models are well-known and frequently used. Despite this, none of the major scientific computing libraries for Python such as SciPy or statistical modules like scikit-learn or statsmodels contained generic implementations of either. A major factor in this exclusion is likely the high level of stability and consistency these packages guarantee. Mixture models and HMMs are not so much single models but rather recipes for creating models. As a result, implementing these models for arbitrary distributions is not trivial, so these packages often sacrifice generality to support training methods for common use cases. For example, scikit-learn implements mixture models where all subpopulations are restricted to normal distributions. Other more specialized packages like hmm-learn and pomegranate are more flexible, but they still limit their built-in support to a relatively small number of common distributions, including normal, exponential, categorical, and Poisson, among others. Furthermore, to support these additional features these packages implement custom APIs which may pose a barrier to users who are already comfortable with the interface of SciPy's statistical module.

We therefore sought to create lightweight implementations of mixture models and HMMs which are available in the packages MixMod and Homomorph, respectively. A key design goal was to ensure these packages were both immediately accessible but also easily extensible. Thus, both packages conform to the SciPy API for specifying distributions, which allows use of its large number of distributions but also permits advanced users to easily implement custom distributions as needed. Fitting models parameterized by arbitrary distributions to data remains a significant challenge, however. MixMod supports fitting models whose subpopulations are parameterized by roughly a dozen distinct distributions, including several common continuous and discrete distributions. Homomorph has no built-in methods for fitting models. We instead wrote an extensive tutorial that covers the theory and implementation of several model fitting approaches for specific distributions. This tutorial is the centerpiece of a series of tutorials for both MixMod which demonstrate their APIs and common applications through a series of examples. Our hope is together these packages and tutorials will bridge the gap between beginner and advanced users by illustrating how complex probabilistic models are constructed from simple pieces.

The tutorials are available alongside the source code for these packages on GitHub. Though each is largely independent of the others, they follow a logical progression. For example, both Mixmod and Homomorph have tutorials which serve as brief introductions to the theory, applications, and APIs for their respective models. Homomorph then has two additional tutorials. The first discusses a generalization of HMMs called autoregressive HMMs (ARHMMs), and the second covers methods for training HMMs. For brevity, only the training tutorial is adapted from its current form in the following section. As the tutorial is a self-contained document with an introduction and conclusion, it is presented without further commentary.
